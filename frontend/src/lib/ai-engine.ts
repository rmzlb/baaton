/**
 * Baaton AI Engine v2 ‚Äî Vercel AI SDK (@ai-sdk/google)
 *
 * Migrated from @google/generative-ai to Vercel AI SDK for:
 * - Built-in agentic loop (maxSteps)
 * - Typed tool results
 * - Unified provider interface (swap Gemini/Claude/GPT)
 * - Proper token usage from response metadata
 * - Automatic retry handling
 *
 * Keeps all existing features:
 * - State machine integration (ai-state.ts)
 * - Tool masking (5 contexts via ai-skills.ts)
 * - Conversation summarization
 * - Rate limiting + token budget
 * - 5-block Manus system prompt
 */

import { generateText, jsonSchema, type CoreMessage, type CoreTool } from 'ai';
import { createGoogleGenerativeAI } from '@ai-sdk/google';
import type { Issue, Project, Milestone } from './types';
import { getToolsForContext, type SkillContext } from './ai-skills';
import { executeSkill } from './ai-executor';
import type { SkillResult } from './ai-skills';
import {
  type AIStateContext,
  createInitialState,
  transition,
  stateToSkillContext,
  checkRateLimit,
  estimateTokens,
  checkBudget,
  summarizeHistory,
} from './ai-state';

// ‚îÄ‚îÄ‚îÄ API Key (fetched from backend) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
import { resolveApiOrigin } from './api-origin';
let _cachedApiKey: string | null = null;
const API_URL = resolveApiOrigin();

async function getGeminiApiKey(authToken?: string): Promise<string> {
  if (_cachedApiKey) return _cachedApiKey;
  if (API_URL && authToken) {
    try {
      const res = await fetch(`${API_URL}/api/v1/ai/key`, {
        headers: { Authorization: `Bearer ${authToken}` },
        signal: AbortSignal.timeout(3000),
      });
      if (res.ok) {
        const data = await res.json();
        if (data.key) {
          _cachedApiKey = data.key;
          return _cachedApiKey;
        }
      }
    } catch { /* backend unreachable */ }
  }
  throw new Error('AI non configur√©. Cl√© API manquante.');
}

// ‚îÄ‚îÄ‚îÄ Errors ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
export class RateLimitError extends Error {
  constructor() {
    super('Rate limit exceeded ‚Äî please wait a moment before sending another message.');
    this.name = 'RateLimitError';
  }
}

function mapProviderErrorToUserMessage(errorLike: unknown): string {
  const msg = errorLike instanceof Error ? errorLike.message : String(errorLike || '');

  if (msg.includes('429') || msg.includes('RESOURCE_EXHAUSTED')) {
    return 'Rate limited ‚Äî wait a moment and try again.';
  }
  if (msg.includes('403') || msg.includes('API_KEY') || msg.includes('permission')) {
    return 'AI configuration issue (API key/permissions). Please check settings.';
  }
  if (msg.includes('ECONNRESET') || msg.includes('fetch') || msg.includes('network') || msg.includes('Network')) {
    return 'Network issue while contacting AI provider. Please retry.';
  }
  if (msg.toLowerCase().includes('schema') || msg.toLowerCase().includes('object')) {
    return 'AI tool schema mismatch detected. Please retry; if it persists, contact support.';
  }

  return 'AI request failed unexpectedly. Please try again.';
}

// ‚îÄ‚îÄ‚îÄ Convert Gemini Tool Declarations ‚Üí AI SDK Tools ‚îÄ‚îÄ‚îÄ‚îÄ
// Bridge: getToolsForContext returns Gemini format [{functionDeclarations: [...]}]
// AI SDK needs Record<string, CoreTool> with jsonSchema parameters

function convertGeminiPropertyToJsonSchema(prop: any): any {
  if (!prop) return { type: 'string' };
  const schema: any = {};
  switch (prop.type) {
    case 'STRING':
      schema.type = 'string';
      break;
    case 'NUMBER':
      schema.type = 'number';
      break;
    case 'BOOLEAN':
      schema.type = 'boolean';
      break;
    case 'ARRAY':
      schema.type = 'array';
      if (prop.items) {
        schema.items = convertGeminiPropertyToJsonSchema(prop.items);
      }
      break;
    case 'OBJECT':
      schema.type = 'object';
      if (prop.properties) {
        schema.properties = {};
        for (const [k, v] of Object.entries(prop.properties)) {
          schema.properties[k] = convertGeminiPropertyToJsonSchema(v);
        }
      }
      if (prop.required) schema.required = prop.required;
      break;
    default:
      schema.type = 'string';
  }
  if (prop.description) schema.description = prop.description;
  return schema;
}

function buildAISDKTools(
  skillContext: SkillContext,
  executor: (name: string, args: Record<string, unknown>) => Promise<any>,
): Record<string, CoreTool> {
  const geminiTools = getToolsForContext(skillContext);
  const declarations = geminiTools.flatMap((t: any) => t.functionDeclarations || []);
  const tools: Record<string, CoreTool> = {};

  for (const decl of declarations) {
    // Convert Gemini params ‚Üí JSON Schema
    const params = decl.parameters || { type: 'OBJECT', properties: {} };
    const schema = convertGeminiPropertyToJsonSchema(params);

    // Gemini API requires root schema to be { type: "object" } with properties
    // Ensure the root always has type "object" and properties defined
    if (schema.type !== 'object') {
      schema.type = 'object';
    }
    if (!schema.properties) {
      schema.properties = {};
    }
    // Gemini API is strict about OBJECT schemas:
    // - Must have type "object" with properties  
    // - Remove empty required arrays (Gemini rejects them)
    // - Set additionalProperties to prevent SDK from treating as "empty" schema
    if (Array.isArray(schema.required) && schema.required.length === 0) {
      delete schema.required;
    }
    // CRITICAL: The @ai-sdk/google provider's isEmptyObjectSchema() returns true
    // when properties is empty AND no additionalProperties. When true at root,
    // it returns undefined ‚Üí Gemini gets no parameters ‚Üí "should be of type OBJECT" error.
    // Setting additionalProperties to true prevents this.
    if (!schema.additionalProperties) {
      schema.additionalProperties = true;
    }

    // CRITICAL FIX for Gemini "parameters schema should be of type OBJECT" error:
    // The @ai-sdk/google SDK converts jsonSchema back to Gemini format, but can
    // lose the OBJECT type. Ensure schema always has non-empty properties and
    // a _dummy field to prevent the SDK from treating it as an empty schema.
    if (Object.keys(schema.properties || {}).length === 0) {
      schema.properties = { _context: { type: 'string', description: 'Optional context' } };
    }
    
    tools[decl.name] = {
      description: decl.description,
      parameters: jsonSchema(schema),
      execute: async (args: any) => {
        try {
          return await executor(decl.name, args);
        } catch (error) {
          console.error('[AI][ToolInvocationFailed]', {
            tool: decl.name,
            args,
            error: error instanceof Error ? error.message : String(error),
          });
          return {
            success: false,
            error: mapProviderErrorToUserMessage(error),
          };
        }
      },
    };
  }

  return tools;
}

// ‚îÄ‚îÄ‚îÄ Context Builder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

export function buildProjectContext(projects: Project[], allIssues: Record<string, Issue[]>): string {
  const lines: string[] = ['# Current Project Data\n'];

  for (const project of projects) {
    const issues = allIssues[project.id] || [];
    if (issues.length === 0) continue;

    const statusCounts: Record<string, number> = {};
    const priorityCounts: Record<string, number> = {};
    const typeCounts: Record<string, number> = {};
    const categoryCounts: Record<string, number> = {};

    for (const issue of issues) {
      statusCounts[issue.status] = (statusCounts[issue.status] || 0) + 1;
      if (issue.priority) priorityCounts[issue.priority] = (priorityCounts[issue.priority] || 0) + 1;
      typeCounts[issue.type] = (typeCounts[issue.type] || 0) + 1;
      for (const cat of issue.category || []) {
        categoryCounts[cat] = (categoryCounts[cat] || 0) + 1;
      }
    }

    lines.push(`## ${project.prefix} ‚Äî ${project.name} (ID: ${project.id})`);
    lines.push(`Total: ${issues.length} issues`);
    lines.push(`Status: ${Object.entries(statusCounts).map(([k, v]) => `${k}=${v}`).join(', ')}`);
    if (Object.keys(priorityCounts).length > 0) {
      lines.push(`Priority: ${Object.entries(priorityCounts).map(([k, v]) => `${k}=${v}`).join(', ')}`);
    }
    lines.push(`Types: ${Object.entries(typeCounts).map(([k, v]) => `${k}=${v}`).join(', ')}`);
    if (Object.keys(categoryCounts).length > 0) {
      lines.push(`Domains: ${Object.entries(categoryCounts).map(([k, v]) => `${k}=${v}`).join(', ')}`);
    }

    const open = issues.filter((i) => i.status === 'todo' || i.status === 'in_progress' || i.status === 'in_review');
    if (open.length > 0) {
      lines.push(`\nOpen issues:`);
      for (const i of open.slice(0, 30)) {
        const prio = i.priority ? ` [${i.priority}]` : '';
        const cats = (i.category || []).length > 0 ? ` {${(i.category || []).join(',')}}` : '';
        const tags = i.tags.length > 0 ? ` #${i.tags.join(' #')}` : '';
        const type = ` (${i.type})`;
        lines.push(`- ${i.display_id} (uuid:${i.id}) | ${i.status}${prio}${type}${cats}${tags} | ${i.title}`);
      }
      if (open.length > 30) lines.push(`  ... and ${open.length - 30} more`);
    }

    const done = issues
      .filter((i) => i.status === 'done')
      .sort((a, b) => new Date(b.updated_at).getTime() - new Date(a.updated_at).getTime());
    if (done.length > 0) {
      lines.push(`\nRecently done (${done.length} total):`);
      for (const i of done.slice(0, 10)) {
        lines.push(`- ${i.display_id} | ${i.title}`);
      }
    }

    lines.push('');
  }

  return lines.join('\n');
}

// ‚îÄ‚îÄ‚îÄ System Prompt (5-Block Manus Pattern) ‚îÄ‚îÄ‚îÄ‚îÄ

export function buildSystemPrompt(context: string): string {
  const STATIC_BLOCKS = `# BLOCK 1 ‚Äî IDENTITY

Tu es **Baaton AI**, le copilote int√©gr√© √† Baaton ‚Äî un board d'orchestration pour agents IA de d√©veloppement.
Tes utilisateurs sont des **d√©veloppeurs et tech leads** qui utilisent des agents IA (Claude, GPT, Copilot, OpenClaw) pour coder.
Tu comprends : architecture logicielle, sprints agile, dette technique, CI/CD, code review, et orchestration d'agents.

## Contexte Baaton
Baaton = "You orchestrate. AI executes." C'est un Kanban/projet tracker sp√©cialis√© pour :
- Suivre les issues de code (bugs, features, improvements) par projet
- Planifier des sprints et milestones pour des √©quipes dev + agents IA
- Cat√©goriser par domaine technique : FRONT, BACK, API, DB, INFRA, UX, DEVOPS
- G√©rer des tags color√©s pour le contexte (ex: "ElevenLabs", "Auth", "Perf")
- Connecter des agents IA (OpenClaw) pour automatiser le triage et l'ex√©cution

## Ton R√¥le
Tu es le PM assistant de l'√©quipe. Tu ne codes pas, mais tu :
- Tries et priorises les issues intelligemment
- Proposes des milestones r√©alistes bas√©s sur la v√©locit√© et les d√©pendances techniques
- D√©tectes les blockers, la dette technique, et les risques
- G√©n√®res des PRD structur√©s avec specs techniques
- Comprends les cat√©gories FRONT/BACK/API/DB et groupes les issues par domaine

# BLOCK 2 ‚Äî SKILLS & CAPACIT√âS

## Tes Skills (fonctions ex√©cutables) :

### üìã Lecture & Analyse
- **search_issues** ‚Äî Chercher/filtrer des issues (texte, status, priorit√©, cat√©gorie, projet)
- **get_project_metrics** ‚Äî M√©triques d√©taill√©es (v√©locit√©, taux de compl√©tion, distribution)
- **analyze_sprint** ‚Äî Analyse de sprint, v√©locit√©, recommandations

### ‚úèÔ∏è Actions
- **create_issue** ‚Äî Cr√©er une issue (titre, description, type, priorit√©, tags, cat√©gorie)
- **update_issue** ‚Äî Modifier une issue
- **bulk_update_issues** ‚Äî Modifier N issues d'un coup
- **add_comment** ‚Äî Ajouter un commentaire / note sur une issue

### üìÑ G√©n√©ration
- **generate_prd** ‚Äî G√©n√©rer un PRD structur√©

### üéØ Milestone Planning
- **plan_milestones** ‚Äî Auto-group open issues into milestones (propose first, user confirms)
- **create_milestones_batch** ‚Äî Create milestones after confirmation
- **adjust_timeline** ‚Äî Adjust timeline based on new constraint/deadline

## R√®gles d'Ex√©cution
1. **TOUJOURS utiliser tes skills** pour acc√©der aux donn√©es ‚Äî jamais d'hallucination
2. **Actions d'√©criture (update/bulk/comment/milestone)** ‚Üí **PROPOSER puis demander confirmation** avant d'ex√©cuter (exception : create_issue ‚Üí cr√©e directement)
3. **Actions destructives** (suppression) ‚Üí demande confirmation avant
4. **Bulk updates** ‚Üí liste les changements AVANT d'ex√©cuter
5. **Cite les display_id** (ex: HLM-42) quand tu mentionnes des issues
6. **Pour update/bulk** ‚Üí utilise l'UUID (pas le display_id)
7. **R√©solution de projet** : quand l'utilisateur dit un nom ("helmai", "sqare"), matche avec le prefix
8. **Cr√©ation d'issue** : par d√©faut status=backlog (pas todo)
9. **Qualification obligatoire** : d√©duis type/priority/category si l'utilisateur ne les pr√©cise pas

## Workflow PM (pertinent)
- **Analyser** : r√©sumer le volume + urgents + in_review + blockers
- **Qualifier** : regrouper par domaine (FRONT/BACK/API/DB/INFRA/UX)
- **Proposer** : milestones sp√©cifiques avec dates cibles
- **Sprints** : placer urgents + in_progress en Sprint 1/2
- **Valider** : demander confirmation avant d'appliquer

## Format de Sortie
- IDs exacts : UUID pour update/delete, display_id pour citation
- Apr√®s chaque action, confirme avec le r√©sultat (display_id + changement)
- Listes > 10 items : r√©sum√© + top 5 en d√©tail
- Ne r√©ponds JAMAIS avec des donn√©es que tu n'as pas obtenues via un skill

## Milestone Planning Flow
1. **plan_milestones** ‚Üí retourne proposed_milestones group√©s avec target_dates
2. Pr√©sente le plan format√© au user
3. Demande confirmation
4. Sur confirmation ‚Üí **create_milestones_batch** avec les donn√©es exactes du plan
5. Ne rappelle PAS plan_milestones sur confirmation
6. Si l'utilisateur demande d'ajuster un planning existant: utilise **adjust_timeline**
7. Si un tool milestone est indisponible/√©choue: explique clairement l'√©chec, puis fallback sur **search_issues** + **get_project_metrics** pour proposer un plan manuel

## Sprint / Planning Guidance
- Pour questions sprint: utilise **analyze_sprint** et/ou **get_project_metrics** avant de conclure
- Si donn√©es incompl√®tes: dis explicitement ce qui manque au lieu d'inventer

## Issue Creation
1. Si projet ambigu ‚Üí demande
2. Remplis un max automatiquement (type, priorit√©, cat√©gorie, tags)
3. NE DEMANDE PAS de confirmation ‚Äî cr√©e directement
4. Apr√®s : propose d'ajouter des images via ‚åòV ou drag & drop
5. **Titre** ‚Äî R√àGLE ABSOLUE, SANS EXCEPTION :
   - Z√âRO brackets, Z√âRO prefix projet, Z√âRO tag dans le titre
   - ‚ùå INTERDIT : "[SQX][BUG] Fix auth" / "[HLM][TECH] Refactor" / "[ARCHI] Migration" / "SQX: Fix" / "HLM - Fix"
   - ‚úÖ CORRECT : "Fix auth token refresh on expired sessions"
   - ‚úÖ CORRECT : "Migration catalogue au niveau Organisation"
   - Le type (BUG/FEATURE/etc.) est dans le champ \`type\`, la cat√©gorie dans \`category\`, le projet dans \`project_id\`.
   - Ne JAMAIS dupliquer ces infos dans le titre ‚Äî elles sont redondantes.
6. **Pas de doublon** : v√©rifie via search_issues si une issue similaire existe d√©j√† avant de cr√©er

# BLOCK 3 ‚Äî COMMUNICATION

- R√©ponds dans la langue de l'utilisateur (FR si fran√ßais, EN si anglais)
- Parle comme un tech lead, pas comme un PM corporate
- Concis, actionnable, Markdown. Pas de bullshit, pas de fluff.
- Bullet points > paragraphes
- M√©triques concr√®tes + pourcentages
- \`backticks\` pour les termes techniques
- Flag les blockers et la dette technique proactivement
- Emojis : ‚úÖ done, üîÑ in progress, üìã todo, üö® urgent, ‚è∏Ô∏è backlog, üêõ bug, ‚ú® feature`;

  const DYNAMIC_BLOCKS = `# BLOCK 4 ‚Äî DONN√âES PROJET (DYNAMIQUE)

${context}

# BLOCK 5 ‚Äî OBJECTIFS ACTUELS

Aide l'utilisateur √† √™tre productif. Ex√©cute efficacement. Propose des insights (bottlenecks, priorit√©s mal calibr√©es). Sois proactif.`;

  return `${STATIC_BLOCKS}\n\n${DYNAMIC_BLOCKS}`;
}

// ‚îÄ‚îÄ‚îÄ Types ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

export interface AIResponse {
  text: string;
  skillsExecuted: SkillResult[];
  usage: {
    inputTokens: number;
    outputTokens: number;
    totalTokens: number;
    turnCount: number;
  };
  stateContext: AIStateContext;
}

const APPROVAL_REQUIRED_SKILLS = new Set([
  'create_issue',
  'update_issue',
  'bulk_update_issues',
  'add_comment',
  'create_milestones_batch',
]);

interface PmFullReviewIssue {
  id: string;
  display_id: string;
  title: string;
  project_id: string;
  project_name: string;
  project_prefix: string;
  status: string;
  priority: string | null;
  created_at: string;
  updated_at: string;
  assignee_ids: string[];
  category: string[];
  tags: string[];
}

interface PmFullReviewBucket {
  key: string;
  name: string;
  issue_ids: string[];
  issues: PmFullReviewIssue[];
}

interface PmFullReviewSprint {
  key: string;
  name: string;
  start_date: string;
  end_date: string;
  issue_ids: string[];
  issues: PmFullReviewIssue[];
}

interface PmFullReviewProject {
  project_id: string;
  project_name: string;
  project_prefix: string;
  open_issue_count: number;
  milestones: PmFullReviewBucket[];
  sprints: PmFullReviewSprint[];
}

interface PmFullReviewSuggestion {
  rank: number;
  reason: string;
  issue: PmFullReviewIssue;
}

interface PmFullReviewData {
  generated_at: string;
  horizon_days: number;
  sprint_length_days: number;
  period: {
    start_date: string;
    end_date: string;
  };
  sprint_windows: Array<{
    key: string;
    name: string;
    start_date: string;
    end_date: string;
  }>;
  summary: {
    project_count: number;
    open_issue_count: number;
    milestone_a_count: number;
    milestone_b_count: number;
    milestone_c_count: number;
    sprint1_count: number;
    sprint2_count: number;
    sprint3_count: number;
    priority_suggestions_count: number;
  };
  projects: PmFullReviewProject[];
  priority_suggestions: PmFullReviewSuggestion[];
}

type ApiClientType = {
  post: <T>(path: string, body: unknown) => Promise<T>;
  issues: {
    listByProject: (id: string, params?: Record<string, unknown>) => Promise<Issue[]>;
    create: (body: Record<string, unknown>) => Promise<Issue>;
    update: (id: string, body: Record<string, unknown>) => Promise<Issue>;
    delete: (id: string) => Promise<void>;
  };
  comments: {
    create: (issueId: string, body: { content: string; author_name: string }) => Promise<unknown>;
  };
  projects: {
    list: () => Promise<Project[]>;
  };
  milestones: {
    listByProject: (projectId: string) => Promise<Milestone[]>;
    create: (projectId: string, body: { name: string; description?: string; target_date?: string; status?: string }) => Promise<Milestone>;
    update: (id: string, body: Partial<Pick<Milestone, 'name' | 'description' | 'target_date' | 'status'>>) => Promise<Milestone>;
    delete: (id: string) => Promise<void>;
  };
};

function isPmFullReviewPrompt(message: string): boolean {
  const text = message.toLowerCase();
  const planningWord = text.includes('plan') || text.includes('planning') || text.includes('analy') || text.includes('analyse');
  const milestoneWord = text.includes('milestone') || text.includes('jalon');
  const sprintWord = text.includes('sprint');
  return planningWord && milestoneWord && sprintWord;
}

function renderIssueLine(issue: PmFullReviewIssue): string {
  const prio = issue.priority ? ` [${issue.priority}]` : '';
  const tags = issue.tags?.length ? ` #${issue.tags.join(' #')}` : '';
  const category = issue.category?.length ? ` {${issue.category.join(', ')}}` : '';
  return `- \`${issue.display_id}\` (${issue.id}) ‚Äî ${issue.status}${prio}${category}${tags} ‚Äî ${issue.title}`;
}

function renderPmFullReviewMarkdown(plan: PmFullReviewData): string {
  const lines: string[] = [
    '## PM Full Review (deterministic planner)',
    `- Generated: ${plan.generated_at}`,
    `- Horizon: ${plan.period.start_date} ‚Üí ${plan.period.end_date} (${plan.horizon_days} days)`,
    `- Sprint length: ${plan.sprint_length_days} days`,
    `- Projects: ${plan.summary.project_count} | Open issues: ${plan.summary.open_issue_count}`,
    `- Milestones ‚Üí A:${plan.summary.milestone_a_count} | B:${plan.summary.milestone_b_count} | C:${plan.summary.milestone_c_count}`,
    `- Sprints ‚Üí S1:${plan.summary.sprint1_count} | S2:${plan.summary.sprint2_count} | S3:${plan.summary.sprint3_count}`,
    '',
  ];

  for (const project of plan.projects) {
    lines.push(`### ${project.project_prefix} ‚Äî ${project.project_name} (${project.project_id})`);
    lines.push(`Open issues: **${project.open_issue_count}**`);
    lines.push('');

    lines.push('#### Milestones');
    for (const milestone of project.milestones) {
      lines.push(`- **${milestone.name}** (${milestone.issue_ids.length})`);
      if (milestone.issue_ids.length > 0) {
        lines.push(`  - IDs: ${milestone.issue_ids.map((id) => `\`${id}\``).join(', ')}`);
        milestone.issues.forEach((issue) => lines.push(`  ${renderIssueLine(issue)}`));
      } else {
        lines.push('  - _No issue in this bucket_');
      }
    }

    lines.push('');
    lines.push('#### Sprints');
    for (const sprint of project.sprints) {
      lines.push(`- **${sprint.name}** (${sprint.start_date} ‚Üí ${sprint.end_date}) ‚Äî ${sprint.issue_ids.length} issues`);
      if (sprint.issue_ids.length > 0) {
        lines.push(`  - IDs: ${sprint.issue_ids.map((id) => `\`${id}\``).join(', ')}`);
        sprint.issues.forEach((issue) => lines.push(`  ${renderIssueLine(issue)}`));
      } else {
        lines.push('  - _No issue in this sprint_');
      }
    }

    lines.push('');
  }

  lines.push('### Top 10 Priority Suggestions');
  if (!plan.priority_suggestions.length) {
    lines.push('- No priority suggestion available.');
  } else {
    for (const suggestion of plan.priority_suggestions.slice(0, 10)) {
      lines.push(
        `${suggestion.rank}. \`${suggestion.issue.display_id}\` (${suggestion.issue.id}) ‚Äî **${suggestion.issue.title}**`,
      );
      lines.push(`   - Reason: ${suggestion.reason}`);
    }
  }

  return lines.join('\n');
}

function buildLegacyPmFallback(projects: Project[], allIssuesByProject: Record<string, Issue[]>): string {
  const allIssues = Object.values(allIssuesByProject).flat();
  const openIssues = allIssues.filter((i: any) => !['done', 'cancelled'].includes(i.status));
  const now = new Date();

  const urgent = openIssues.filter((i: any) => i.priority === 'urgent');
  const inProgress = openIssues.filter((i: any) => i.status === 'in_progress');
  const review = openIssues.filter((i: any) => i.status === 'in_review');
  const backlog = openIssues.filter((i: any) => ['backlog', 'todo'].includes(i.status));

  const next = (d: number) => {
    const x = new Date(now);
    x.setDate(x.getDate() + d);
    return x.toISOString().slice(0, 10);
  };

  return [
    '## PM Full Review (deterministic fallback)',
    `- Projects: ${projects.length}`,
    `- Open tickets: ${openIssues.length}`,
    `- Urgent: ${urgent.length} | In progress: ${inProgress.length} | In review: ${review.length} | Backlog/Todo: ${backlog.length}`,
    '',
    '## Proposed Milestones',
    `1) Stabilization & Hotfixes (target ${next(7)}) ‚Äî focus urgent + blockers`,
    `2) Active Delivery (target ${next(21)}) ‚Äî close in_progress + in_review`,
    `3) Backlog Acceleration (target ${next(42)}) ‚Äî top priority backlog/todo`,
    '',
    '## Suggested Sprint Allocation',
    `- Sprint 1 (now ‚Üí ${next(14)}): urgent + oldest in_progress`,
    `- Sprint 2 (${next(14)} ‚Üí ${next(28)}): remaining active + critical backlog`,
    `- Sprint 3 (${next(28)} ‚Üí ${next(42)}): feature backlog + polish`,
    '',
    '## Priority Recommendations',
    '- Keep all production-impact bugs as urgent/high until resolved',
    '- Promote stale in_progress (>7 days) to high and assign explicit owner',
    '- Split oversized backlog items into sub-issues before sprint planning',
    '',
    'If you want, I can now generate a project-by-project mapping (issue IDs grouped under each milestone).',
  ].join('\n');
}

// ‚îÄ‚îÄ‚îÄ Main Generate Function (Vercel AI SDK) ‚îÄ‚îÄ‚îÄ

export async function generateAIResponse(
  userMessage: string,
  projects: Project[],
  allIssuesByProject: Record<string, Issue[]>,
  conversationHistory: { role: string; content: string }[],
  apiClient: ApiClientType,
  stateContext?: AIStateContext,
  authToken?: string,
  options?: { requireApproval?: boolean },
): Promise<AIResponse> {
  // ‚îÄ‚îÄ Rate Limiting ‚îÄ‚îÄ
  const rateCheck = checkRateLimit();
  if (!rateCheck.allowed) {
    throw new RateLimitError();
  }

  const requireApproval = options?.requireApproval ?? false;

  // ‚îÄ‚îÄ State Machine: init or use provided ‚îÄ‚îÄ
  let state = stateContext ? { ...stateContext } : createInitialState();
  state = transition(state, { type: 'USER_MESSAGE', tokens: estimateTokens(userMessage) });

  // ‚îÄ‚îÄ Budget check ‚îÄ‚îÄ
  const budget = checkBudget(state);
  if (!budget.ok) {
    return {
      text: `‚ö†Ô∏è ${budget.warning}`,
      skillsExecuted: [],
      usage: { inputTokens: 0, outputTokens: 0, totalTokens: 0, turnCount: state.usage.turnCount },
      stateContext: state,
    };
  }

  // ‚îÄ‚îÄ Build context & prompt ‚îÄ‚îÄ
  const context = buildProjectContext(projects, allIssuesByProject);
  const systemPrompt = buildSystemPrompt(context);

  // ‚îÄ‚îÄ Conversation summarization ‚îÄ‚îÄ
  const optimizedHistory = summarizeHistory(conversationHistory);

  // ‚îÄ‚îÄ Build messages ‚îÄ‚îÄ
  const messages: CoreMessage[] = optimizedHistory.slice(-8).map((m) => ({
    role: (m.role === 'user' ? 'user' : 'assistant') as 'user' | 'assistant',
    content: m.content,
  }));
  messages.push({ role: 'user', content: userMessage });

  // ‚îÄ‚îÄ Tool masking from state ‚îÄ‚îÄ
  const skillContext = stateToSkillContext(state);
  const skillsExecuted: SkillResult[] = [];

  // Deterministic PM full-review mode (backend endpoint, zero Gemini tool-calling)
  if (isPmFullReviewPrompt(userMessage)) {
    let text: string;

    try {
      const plan = await apiClient.post<PmFullReviewData>('/ai/pm-full-review', {
        project_ids: projects.length ? projects.map((p) => p.id) : undefined,
        horizon_days: 42,
        sprint_length_days: 14,
      });

      text = renderPmFullReviewMarkdown(plan);
      skillsExecuted.push({
        skill: 'pm_full_review',
        success: true,
        summary: `Generated PM plan for ${plan.summary.project_count} project(s)`,
        data: plan,
      });
    } catch (error) {
      console.warn('[AI][PmFullReviewEndpointFallback]', {
        error: error instanceof Error ? error.message : String(error),
      });

      // Safety net: keep local deterministic fallback if backend endpoint fails.
      text = buildLegacyPmFallback(projects, allIssuesByProject);
      skillsExecuted.push({
        skill: 'pm_full_review',
        success: false,
        summary: 'Used fallback PM review renderer',
        error: error instanceof Error ? error.message : String(error),
      });
    }

    const outputTokens = estimateTokens(text);
    const inputTokens = estimateTokens(userMessage);
    state = transition(state, { type: 'AI_RESPONSE', tokens: outputTokens });

    return {
      text,
      skillsExecuted,
      usage: {
        inputTokens,
        outputTokens,
        totalTokens: inputTokens + outputTokens,
        turnCount: state.usage.turnCount,
      },
      stateContext: state,
    };
  }

  // ‚îÄ‚îÄ Get API key & create provider ‚îÄ‚îÄ
  const apiKey = await getGeminiApiKey(authToken);
  const google = createGoogleGenerativeAI({ apiKey });

  // ‚îÄ‚îÄ Build tools with executor bridge ‚îÄ‚îÄ
  const executor = async (name: string, args: Record<string, unknown>) => {
    state = transition(state, { type: 'SKILL_STARTED', name });
    const startTime = performance.now();

    if (requireApproval && APPROVAL_REQUIRED_SKILLS.has(name)) {
      const pendingData = { pending: true, args } as Record<string, unknown>;
      const executionTime = Math.round(performance.now() - startTime);
      const pendingResult: SkillResult = {
        skill: name,
        success: true,
        summary: 'Pending approval',
        data: pendingData,
      };
      skillsExecuted.push({ ...pendingResult, executionTimeMs: executionTime } as any);
      state = transition(state, { type: 'SKILL_COMPLETED', name, data: pendingData });
      return pendingData;
    }

    try {
      const result = await executeSkill(name, args, apiClient, allIssuesByProject, projects);
      const executionTime = Math.round(performance.now() - startTime);
      const enriched = { ...result, executionTimeMs: executionTime };
      skillsExecuted.push(enriched);

      if (result.success) {
        state = transition(state, { type: 'SKILL_COMPLETED', name, data: result.data });
      } else {
        console.warn('[AI][SkillFailed]', { name, args, error: result.error, summary: result.summary });
        state = transition(state, { type: 'SKILL_FAILED', name, error: result.error || 'Unknown error' });
      }

      return result.data || { success: result.success, error: result.error };
    } catch (error) {
      const executionTime = Math.round(performance.now() - startTime);
      console.error('[AI][SkillCrash]', {
        name,
        args,
        executionTimeMs: executionTime,
        error: error instanceof Error ? error.message : String(error),
      });

      const friendly = mapProviderErrorToUserMessage(error);
      const fallbackResult: SkillResult = {
        skill: name,
        success: false,
        error: friendly,
        summary: `${name} failed safely`,
      };
      skillsExecuted.push({ ...fallbackResult, executionTimeMs: executionTime } as any);
      state = transition(state, { type: 'SKILL_FAILED', name, error: friendly });
      return { success: false, error: friendly };
    }
  };

  const tools = buildAISDKTools(skillContext, executor);

  try {
    // ‚îÄ‚îÄ Vercel AI SDK: generateText with tools + maxSteps ‚îÄ‚îÄ
    // maxSteps = 5 ‚Üí agentic loop (same as our old 5-round loop)
    // The SDK handles: tool call ‚Üí execute ‚Üí feed result ‚Üí get next response
    const result = await generateText({
      model: google('gemini-3-flash-preview', {
        // Disable structuredOutputs to avoid strict schema validation issues
        // with Gemini API's OBJECT type requirements
        structuredOutputs: false,
      }),
      system: systemPrompt,
      messages,
      tools,
      maxSteps: 5,
      temperature: 0.4,
      maxTokens: 2000,
    });

    // ‚îÄ‚îÄ Track usage from response metadata ‚îÄ‚îÄ
    const usage = result.usage || { promptTokens: 0, completionTokens: 0, totalTokens: 0 };
    const inputTokens = usage.promptTokens || estimateTokens(systemPrompt + userMessage);
    const outputTokens = usage.completionTokens || estimateTokens(result.text || '');

    state = transition(state, { type: 'AI_RESPONSE', tokens: outputTokens });

    const pendingSkills = skillsExecuted.filter((s) => (s.data as any)?.pending);
    if (pendingSkills.length > 0) {
      const pendingList = pendingSkills.map((s) => s.skill).join(', ');
      return {
        text: `‚ö†Ô∏è Validation requise avant d'ex√©cuter: ${pendingList}.`,
        skillsExecuted,
        usage: {
          inputTokens,
          outputTokens,
          totalTokens: inputTokens + outputTokens,
          turnCount: state.usage.turnCount,
        },
        stateContext: state,
      };
    }

    const fallbackSkillText = skillsExecuted.length > 0
      ? skillsExecuted
          .map((s) => `‚Ä¢ ${s.summary}${s.success ? '' : s.error ? ` (${s.error})` : ''}`)
          .join('\n')
      : "Je n'ai pas pu g√©n√©rer de r√©ponse. R√©essaie avec plus de d√©tails.";

    return {
      text: result.text?.trim() ? result.text : fallbackSkillText,
      skillsExecuted,
      usage: {
        inputTokens,
        outputTokens,
        totalTokens: inputTokens + outputTokens,
        turnCount: state.usage.turnCount,
      },
      stateContext: state,
    };
  } catch (err: any) {
    state = transition(state, { type: 'ERROR', error: String(err) });

    const msg = err?.message || String(err);
    if (msg.includes('429') || msg.includes('RESOURCE_EXHAUSTED')) {
      throw new RateLimitError();
    }

    // Gemini function-calling can fail on schema validation in some deployments.
    // Fail soft with a NO-TOOLS fallback that still produces actionable PM output.
    const lowerMsg = msg.toLowerCase();
    const isToolSchemaError =
      (lowerMsg.includes('schema') && lowerMsg.includes('function')) ||
      lowerMsg.includes('functiondeclaration') ||
      lowerMsg.includes('parameters schema should be of type object') ||
      lowerMsg.includes('tool schema mismatch');

    if (isToolSchemaError) {
      console.warn('[AI][GenerateTextFallbackNoTools]', {
        reason: 'tool schema mismatch',
        skillContext,
        message: msg,
      });

      try {
        const [metricsResult, prioritiesResult] = await Promise.all([
          executeSkill('get_project_metrics', {}, apiClient, allIssuesByProject, projects),
          executeSkill('suggest_priorities', {}, apiClient, allIssuesByProject, projects),
        ]);

        // Hard fallback: DO NOT call Gemini again.
        // Build a deterministic PM review from live metrics so user always gets output.
        const m: any = metricsResult?.data || {};
        const p: any = prioritiesResult?.data || {};
        const projectCount = Array.isArray(m.projects) ? m.projects.length : (m.project_count ?? 0);
        const openCount = m.open_issues ?? m.openCount ?? 0;
        const doneCount = m.done_issues ?? m.doneCount ?? 0;
        const completion = m.completion_rate ?? m.completionRate ?? null;
        const suggestions = Array.isArray(p.suggestions) ? p.suggestions : [];

        const lines: string[] = [
          '‚ö†Ô∏è AI function-calling indisponible temporairement ‚Äî mode fallback activ√©.',
          '',
          '## Revue PM (fallback live data)',
          `- Projets analys√©s: ${projectCount}`,
          `- Tickets ouverts: ${openCount}`,
          `- Tickets termin√©s: ${doneCount}`,
          completion != null ? `- Taux de completion: ${completion}%` : '- Taux de completion: n/a',
          '',
          '## Priorit√©s sugg√©r√©es',
        ];

        if (suggestions.length === 0) {
          lines.push('- Aucune suggestion automatique disponible.');
        } else {
          for (const s of suggestions.slice(0, 10)) {
            if (typeof s === 'string') lines.push(`- ${s}`);
            else lines.push(`- ${s.title || s.issue || 'Issue'} ‚Üí ${s.priority || 'review'}`);
          }
        }

        lines.push('', '## Next', '- Rafra√Æchir la session puis relancer pour plan milestones/sprints d√©taill√©.');

        const text = lines.join('\n');
        const outputTokens = estimateTokens(text);
        const inputTokens = estimateTokens(userMessage);

        state = transition(state, { type: 'AI_RESPONSE', tokens: outputTokens });

        return {
          text,
          skillsExecuted,
          usage: {
            inputTokens,
            outputTokens,
            totalTokens: inputTokens + outputTokens,
            turnCount: state.usage.turnCount,
          },
          stateContext: state,
        };
      } catch (retryErr: any) {
        console.error('[AI][GenerateTextRetryFailed]', {
          message: retryErr?.message || String(retryErr),
          skillContext,
        });
      }
    }

    const friendly = mapProviderErrorToUserMessage(err);
    console.error('[AI][GenerateTextFailed]', {
      message: msg,
      friendly,
      skillContext,
      skillCount: Object.keys(tools).length,
    });

    throw new Error(friendly);
  }
}
