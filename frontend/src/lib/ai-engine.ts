/**
 * Baaton AI Engine â€” Gemini function calling with skills.
 * Uses @google/generative-ai SDK for proper browser CORS support.
 */

import { GoogleGenerativeAI, type Content, type Part } from '@google/generative-ai';
import type { Issue, Project, Milestone } from './types';
import { SKILL_TOOLS } from './ai-skills';
import { executeSkill } from './ai-executor';
import type { SkillResult } from './ai-skills';

const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY || '';
const GEMINI_MODEL = 'gemini-2.0-flash';

// â”€â”€â”€ Context Builder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function buildProjectContext(projects: Project[], allIssues: Record<string, Issue[]>): string {
  const lines: string[] = ['# Current Project Data\n'];

  for (const project of projects) {
    const issues = allIssues[project.id] || [];
    if (issues.length === 0) continue;

    const statusCounts: Record<string, number> = {};
    const priorityCounts: Record<string, number> = {};

    for (const issue of issues) {
      statusCounts[issue.status] = (statusCounts[issue.status] || 0) + 1;
      if (issue.priority) priorityCounts[issue.priority] = (priorityCounts[issue.priority] || 0) + 1;
    }

    lines.push(`## ${project.prefix} â€” ${project.name} (ID: ${project.id})`);
    lines.push(`Total: ${issues.length} issues`);
    lines.push(`Status: ${Object.entries(statusCounts).map(([k, v]) => `${k}=${v}`).join(', ')}`);
    if (Object.keys(priorityCounts).length > 0) {
      lines.push(`Priority: ${Object.entries(priorityCounts).map(([k, v]) => `${k}=${v}`).join(', ')}`);
    }

    // List open issues (todo + in_progress) with IDs for reference
    const open = issues.filter((i) => i.status === 'todo' || i.status === 'in_progress' || i.status === 'in_review');
    if (open.length > 0) {
      lines.push(`\nOpen issues:`);
      for (const i of open.slice(0, 30)) {
        const prio = i.priority ? ` [${i.priority}]` : '';
        const cats = (i.category || []).length > 0 ? ` {${(i.category || []).join(',')}}` : '';
        lines.push(`- ${i.display_id} (uuid:${i.id}) | ${i.status}${prio}${cats} | ${i.title}`);
      }
      if (open.length > 30) lines.push(`  ... and ${open.length - 30} more`);
    }

    // Recent done
    const done = issues
      .filter((i) => i.status === 'done')
      .sort((a, b) => new Date(b.updated_at).getTime() - new Date(a.updated_at).getTime());
    if (done.length > 0) {
      lines.push(`\nRecently done (${done.length} total):`);
      for (const i of done.slice(0, 10)) {
        lines.push(`- ${i.display_id} | ${i.title}`);
      }
    }

    lines.push('');
  }

  return lines.join('\n');
}

// â”€â”€â”€ System Prompt (5-Block Manus Pattern) â”€â”€â”€â”€
// Block 1: STATIC â€” Identity & Role (never changes, max KV-cache hits)
// Block 2: STATIC â€” Skills & Rules
// Block 3: SEMI-STATIC â€” Communication Rules
// Block 4: DYNAMIC â€” Project Context (changes per session)
// Block 5: DYNAMIC â€” Current Goals (completion bias at end)

function buildSystemPrompt(context: string): string {
  return `# BLOCK 1 â€” IDENTITY

Tu es **Baaton AI**, l'assistant intelligent du board Baaton.
Tu es un PM assistant expert : tu comprends le product management, le dÃ©veloppement logiciel, et les mÃ©thodologies agile.
Tu as un accÃ¨s complet aux donnÃ©es en temps rÃ©el et peux exÃ©cuter des actions.

# BLOCK 2 â€” SKILLS & CAPACITÃ‰S

## Tes 11 Skills (fonctions exÃ©cutables) :

### ğŸ“‹ Lecture & Analyse
- **search_issues** â€” Chercher/filtrer des issues (texte, status, prioritÃ©, catÃ©gorie, projet)
- **get_project_metrics** â€” MÃ©triques dÃ©taillÃ©es (vÃ©locitÃ©, taux de complÃ©tion, distribution)
- **analyze_sprint** â€” Analyse de sprint, vÃ©locitÃ©, recommandations pour le prochain sprint

### âœï¸ Actions
- **create_issue** â€” CrÃ©er une issue (titre, description, type, prioritÃ©, tags, catÃ©gorie)
- **update_issue** â€” Modifier une issue (status, prioritÃ©, description, tags, assignÃ©e)
- **bulk_update_issues** â€” Modifier N issues d'un coup (reprioritisation, changement de status en masse)
- **add_comment** â€” Ajouter un commentaire / note sur une issue

### ğŸ“„ GÃ©nÃ©ration
- **generate_prd** â€” GÃ©nÃ©rer un PRD structurÃ© (objectifs, user stories, critÃ¨res d'acceptance, specs techniques)

### ğŸ¯ Milestone Planning
- **plan_milestones** â€” Analyser les tickets ouverts, dÃ©tecter les dÃ©pendances entre issues (par similaritÃ© de titre/description), calculer la vÃ©locitÃ© (issues/semaine), et proposer un plan de milestones avec chemin critique. Ne crÃ©e rien automatiquement â€” propose d'abord, l'utilisateur confirme.
- **create_milestones_batch** â€” CrÃ©er plusieurs milestones et assigner les issues d'un coup. Utiliser APRÃˆS plan_milestones quand l'utilisateur confirme le plan proposÃ©.
- **adjust_timeline** â€” Ajuster la timeline des milestones selon une nouvelle contrainte/deadline. RÃ©cupÃ¨re les milestones, issues, dÃ©pendances et vÃ©locitÃ© pour proposer un replanning rÃ©aliste.

## RÃ¨gles d'ExÃ©cution
1. **TOUJOURS utiliser tes skills** pour accÃ©der aux donnÃ©es â€” jamais d'hallucination
2. **Actions directes** : crÃ©er, modifier, commenter â†’ exÃ©cute immÃ©diatement sans demander confirmation
3. **Actions destructives** (suppression) â†’ demande confirmation avant
4. **Bulk updates** â†’ liste les changements AVANT d'exÃ©cuter
5. **Cite les display_id** (ex: HLM-42) quand tu mentionnes des issues
6. **Pour update/bulk** â†’ utilise l'UUID (pas le display_id)
7. **RÃ©solution de projet** : quand l'utilisateur dit un nom ("helmai", "sqare"), matche avec le prefix du projet

## Comportement pour le Milestone Planning

Quand l'utilisateur demande de planifier des milestones :
1. **Utilise plan_milestones** pour rÃ©cupÃ©rer tous les tickets ouverts
2. **Propose un plan structurÃ©** avec des groupements logiques, des estimations de durÃ©e, et un ordre de prioritÃ©
3. **NE CRÃ‰E PAS les milestones automatiquement** â€” prÃ©sente le plan et demande confirmation
4. **Quand l'utilisateur confirme**, utilise **create_milestones_batch** pour tout crÃ©er d'un coup
5. **Pour ajuster un plan existant**, utilise **adjust_timeline** avec la contrainte spÃ©cifiÃ©e

Format de proposition :
- ğŸ¯ **Milestone 1 : Nom** (cible: date) â€” X issues
  - Liste des issues avec display_id
- ğŸ¯ **Milestone 2 : Nom** (cible: date) â€” Y issues
  - etc.

## Comportement pour la CrÃ©ation d'Issue

Quand l'utilisateur demande de crÃ©er une issue :
1. **Si le projet est ambigu** (pas sur une page projet, ou plusieurs projets possibles) â†’ demande dans quel projet
2. **Remplis un maximum de champs automatiquement** :
   - Titre : clair et concis
   - Description : dÃ©taillÃ©e, structurÃ©e en Markdown, avec contexte
   - Type : dÃ©duis du contenu (bug, feature, improvement, question)
   - PrioritÃ© : dÃ©duis de l'urgence exprimÃ©e
   - CatÃ©gorie : dÃ©duis des mots-clÃ©s techniques (FRONT, BACK, API, DB)
   - Tags : utilise les tags existants du projet si pertinents
3. **NE DEMANDE PAS de confirmation** â€” crÃ©e directement l'issue
4. **AprÃ¨s crÃ©ation**, propose : "ğŸ“ Tu peux ajouter des images en ouvrant l'issue et en collant (âŒ˜V) ou drag & drop"

## CapacitÃ©s de Baaton (ce que tu SAIS faire)
- âœ… PiÃ¨ces jointes : images via paste (âŒ˜V), drag & drop, compression automatique
- âœ… Annotation d'images : outil intÃ©grÃ© (stylo, flÃ¨ches, cercles, texte, 7 couleurs)
- âœ… Lightbox : visualisation plein Ã©cran avec zoom
- âœ… Commentaires avec mentions
- âœ… Description rich text (Markdown, slash commands, toolbar)
- âœ… Tags colorÃ©s (15 couleurs)
- âœ… Deep links (?issue=HLM-42)
- âœ… Raccourcis clavier (J/K naviguer, E Ã©diter, N nouveau, ? aide)

**IMPORTANT** : Ne dis JAMAIS que tu ne peux pas gÃ©rer les images. Baaton supporte les images nativement. Indique Ã  l'utilisateur d'ouvrir l'issue et de coller/glisser les images.

# BLOCK 3 â€” COMMUNICATION

## Langue
- RÃ©ponds dans la langue de l'utilisateur (FR si franÃ§ais, EN si anglais)
- Sois concis, actionnable, structurÃ© (Markdown)
- Utilise des emojis pour les statuts : âœ… done, ğŸ”„ in progress, ğŸ“‹ todo, ğŸš¨ urgent, â¸ï¸ backlog

## Format de RÃ©ponse
- **RÃ©sumÃ©** : bullet points, pas de paragraphes
- **MÃ©triques** : utilise des pourcentages et des chiffres concrets
- **Issues** : cite toujours le display_id (ex: HLM-42)
- **Actions** : confirme ce qui a Ã©tÃ© fait avec le rÃ©sultat

## Weekly Recap (quand demandÃ©)
Fournis un rapport structurÃ© :
1. **ğŸ“Š RÃ©sumÃ©** : X issues crÃ©Ã©es, Y complÃ©tÃ©es, Z en cours
2. **âœ… ComplÃ©tÃ©es** : liste des issues terminÃ©es cette semaine
3. **ğŸ”„ En cours** : issues actives avec leur statut
4. **ğŸš§ Bloqueurs** : issues critiques/urgentes non rÃ©solues
5. **ğŸ“ˆ Tendance** : vÃ©locitÃ© (issues done/semaine), taux de complÃ©tion

# BLOCK 4 â€” DONNÃ‰ES PROJET (DYNAMIQUE)

${context}

# BLOCK 5 â€” OBJECTIFS ACTUELS

Ton objectif principal : aider l'utilisateur Ã  Ãªtre plus productif dans la gestion de ses projets.
- RÃ©ponds prÃ©cisÃ©ment aux questions
- ExÃ©cute les actions demandÃ©es efficacement
- Propose des insights quand c'est pertinent (bottlenecks, prioritÃ©s mal calibrÃ©es)
- Sois proactif : si tu vois un problÃ¨me dans les donnÃ©es, mentionne-le`;
}

// â”€â”€â”€ Gemini SDK Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

interface GeminiContent {
  role: string;
  parts: GeminiPart[];
}

interface GeminiPart {
  text?: string;
  functionCall?: { name: string; args: Record<string, unknown> };
  functionResponse?: { name: string; response: { result: unknown } };
}

interface GeminiFunctionCall {
  name: string;
  args: Record<string, unknown>;
}

// Convert our SKILL_TOOLS format to SDK format
function getToolDeclarations() {
  const tools = SKILL_TOOLS;
  if (!tools || !Array.isArray(tools)) return undefined;
  return tools;
}

async function callGemini(
  contents: GeminiContent[],
  systemPrompt: string,
  _authToken?: string,
): Promise<{
  text?: string;
  functionCalls?: GeminiFunctionCall[];
}> {
  if (!GEMINI_API_KEY) {
    throw new Error('AI non configurÃ©. ClÃ© API manquante.');
  }

  const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
  const model = genAI.getGenerativeModel({
    model: GEMINI_MODEL,
    systemInstruction: systemPrompt,
    tools: getToolDeclarations() as any,
    generationConfig: {
      temperature: 0.4,
      maxOutputTokens: 2000,
      topP: 0.9,
    },
  });

  // Convert our contents to SDK Content format
  const sdkContents: Content[] = contents.map((c) => ({
    role: c.role,
    parts: c.parts.map((p): Part => {
      if (p.text) return { text: p.text };
      if (p.functionCall) return { functionCall: { name: p.functionCall.name, args: p.functionCall.args } } as Part;
      if (p.functionResponse) return { functionResponse: { name: p.functionResponse.name, response: p.functionResponse.response } } as Part;
      return { text: '' };
    }),
  }));

  const result = await model.generateContent({ contents: sdkContents });
  const response = result.response;
  const candidate = response.candidates?.[0];
  if (!candidate) throw new Error('No response from Gemini');

  const parts = candidate.content?.parts || [];
  const textParts = parts.filter((p) => p.text).map((p) => p.text!);
  const functionCalls = parts
    .filter((p) => (p as any).functionCall)
    .map((p) => (p as any).functionCall as GeminiFunctionCall);

  return {
    text: textParts.length > 0 ? textParts.join('\n') : undefined,
    functionCalls: functionCalls.length > 0 ? functionCalls : undefined,
  };
}

// â”€â”€â”€ Main Chat Function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export interface AIResponse {
  text: string;
  skillsExecuted: SkillResult[];
}

type ApiClientType = {
  issues: {
    listByProject: (id: string, params?: Record<string, unknown>) => Promise<Issue[]>;
    create: (body: Record<string, unknown>) => Promise<Issue>;
    update: (id: string, body: Record<string, unknown>) => Promise<Issue>;
    delete: (id: string) => Promise<void>;
  };
  comments: {
    create: (issueId: string, body: { content: string; author_name: string }) => Promise<unknown>;
  };
  projects: {
    list: () => Promise<Project[]>;
  };
  milestones: {
    listByProject: (projectId: string) => Promise<Milestone[]>;
    create: (projectId: string, body: { name: string; description?: string; target_date?: string; status?: string }) => Promise<Milestone>;
    update: (id: string, body: Partial<Pick<Milestone, 'name' | 'description' | 'target_date' | 'status'>>) => Promise<Milestone>;
    delete: (id: string) => Promise<void>;
  };
};

export async function generateAIResponse(
  userMessage: string,
  projects: Project[],
  allIssuesByProject: Record<string, Issue[]>,
  conversationHistory: { role: string; content: string }[],
  apiClient: ApiClientType,
): Promise<AIResponse> {
  const context = buildProjectContext(projects, allIssuesByProject);
  const systemPrompt = buildSystemPrompt(context);
  const skillsExecuted: SkillResult[] = [];

  // Build conversation contents
  const contents: GeminiContent[] = [];

  // Add conversation history (last 8 messages)
  for (const msg of conversationHistory.slice(-8)) {
    contents.push({
      role: msg.role === 'user' ? 'user' : 'model',
      parts: [{ text: msg.content }],
    });
  }

  // Add current user message
  contents.push({
    role: 'user',
    parts: [{ text: userMessage }],
  });

  // Agentic loop â€” keep calling Gemini until we get a text response (max 5 rounds)
  for (let round = 0; round < 5; round++) {
    const response = await callGemini(contents, systemPrompt);

    // If we got function calls, execute them and feed results back
    if (response.functionCalls && response.functionCalls.length > 0) {
      // Add model's function call to conversation
      contents.push({
        role: 'model',
        parts: response.functionCalls.map((fc) => ({
          functionCall: { name: fc.name, args: fc.args },
        })),
      });

      // Execute each function call
      const functionResponseParts: GeminiPart[] = [];

      for (const fc of response.functionCalls) {
        console.log(`[AI Skill] Executing: ${fc.name}`, fc.args);
        const result = await executeSkill(
          fc.name,
          fc.args,
          apiClient,
          allIssuesByProject,
          projects,
        );
        skillsExecuted.push(result);

        functionResponseParts.push({
          functionResponse: {
            name: fc.name,
            response: { result: result.data || { success: result.success, error: result.error } },
          },
        });
      }

      // Feed results back to Gemini
      contents.push({
        role: 'user',
        parts: functionResponseParts,
      });

      // If we also got text, we can return it with the skills
      if (response.text) {
        return { text: response.text, skillsExecuted };
      }

      // Otherwise, loop to get Gemini's interpretation of the results
      continue;
    }

    // No function calls â€” just text
    if (response.text) {
      return { text: response.text, skillsExecuted };
    }

    break;
  }

  return {
    text: "Je n'ai pas pu gÃ©nÃ©rer de rÃ©ponse. RÃ©essaie avec plus de dÃ©tails.",
    skillsExecuted,
  };
}
